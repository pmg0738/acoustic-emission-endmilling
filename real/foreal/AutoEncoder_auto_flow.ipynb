{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "\n",
    "from loadTDMS import *\n",
    "from fft_test import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select caseNum, trainTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "caseNum = 1\n",
    "trainTool = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(rf\"Z:\\200 Produced_data\\MashineLearning\\case_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>caseNum</th>\n",
       "      <th>trainTool</th>\n",
       "      <th>AE_location</th>\n",
       "      <th>fq</th>\n",
       "      <th>fq_num</th>\n",
       "      <th>path_start</th>\n",
       "      <th>path_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>spindle</td>\n",
       "      <td>[5 6]</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  caseNum trainTool AE_location     fq  fq_num  path_start  \\\n",
       "0           0        1         A     spindle  [5 6]       2          51   \n",
       "\n",
       "   path_end  \n",
       "0        60  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# info[info['caseNum'] == caseNum and info['trainTool'] == trainTool]\n",
    "info = info[info['caseNum'] == caseNum]\n",
    "info = info[info['trainTool'] == trainTool]\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get fq_num, path_start, path_end, interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fq_num: 164\n",
      "path_start: 51\n",
      "path_end: 60\n",
      "total_path: 10\n",
      "interval: 1200\n"
     ]
    }
   ],
   "source": [
    "fq_num = info['fq_num'][0]\n",
    "fq_num = fq_num*82\n",
    "print(f\"fq_num: {fq_num}\")\n",
    "\n",
    "path_start = info['path_start'][0]\n",
    "print(f\"path_start: {path_start}\")\n",
    "\n",
    "path_end = info['path_end'][0]\n",
    "print(f\"path_end: {path_end}\")\n",
    "\n",
    "total_path = path_end - path_start + 1\n",
    "print(f\"total_path: {total_path}\")\n",
    "\n",
    "if trainTool ==\"A\":\n",
    "    interval = 1200\n",
    "if trainTool ==\"B\":\n",
    "    interval = 1200\n",
    "if trainTool ==\"C\":\n",
    "    interval = 1023\n",
    "\n",
    "print(f\"interval: {interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TrainD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train D\n",
    "train_d = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\trainD\\case{caseNum}_{trainTool}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print Train data's set number\n",
    "len(train_d)/fq_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TestD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_A = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\testD\\case{caseNum}_{trainTool}_A.npy\")\n",
    "test_B = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\testD\\case{caseNum}_{trainTool}_B.npy\")\n",
    "test_C = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\testD\\case{caseNum}_{trainTool}_C.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552000.0\n",
      "552000.0\n",
      "470580.0\n"
     ]
    }
   ],
   "source": [
    "print(len(test_A)/164) #552000 sets\n",
    "print(len(test_B)/164) #552000 sets\n",
    "print(len(test_C)/164) #470580 sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape for train and test\n",
    "# 164 = fft 200-300kHzのampの返り値の数（0-500kHz:820個) \n",
    "train_d = train_d.reshape(int(len(train_d)/fq_num),fq_num)\n",
    "test_A = test_A.reshape(int(len(test_A)/fq_num),fq_num)\n",
    "test_B = test_B.reshape(int(len(test_B)/fq_num),fq_num)\n",
    "test_C = test_C.reshape(int(len(test_C)/fq_num),fq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 164)\n",
      "(552000, 164)\n",
      "(552000, 164)\n",
      "(470580, 164)\n"
     ]
    }
   ],
   "source": [
    "print(train_d.shape)\n",
    "print(test_A.shape)\n",
    "print(test_B.shape)\n",
    "print(test_C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 164, 32)           256       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 164, 32)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 164, 16)           3600      \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 164, 16)          1808      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 164, 16)           0         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 164, 32)          3616      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1DT  (None, 164, 1)           225       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,505\n",
      "Trainable params: 9,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#モデルの定義\n",
    "model =keras.initializers.Initializer()\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(train_d.shape[1],1)),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=1, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=1, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=1, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=1, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "108/108 [==============================] - 9s 72ms/step - loss: 0.1663 - val_loss: 0.0124\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 7s 63ms/step - loss: 0.0355 - val_loss: 0.0066\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 7s 69ms/step - loss: 0.0277 - val_loss: 0.0058\n",
      "Epoch 4/200\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.0246 - val_loss: 0.0049\n",
      "Epoch 5/200\n",
      "108/108 [==============================] - 7s 68ms/step - loss: 0.0223 - val_loss: 0.0045\n",
      "Epoch 6/200\n",
      "108/108 [==============================] - 7s 65ms/step - loss: 0.0208 - val_loss: 0.0049\n",
      "Epoch 7/200\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 0.0192 - val_loss: 0.0055\n",
      "Epoch 8/200\n",
      "108/108 [==============================] - 7s 67ms/step - loss: 0.0178 - val_loss: 0.0069\n",
      "Epoch 9/200\n",
      "108/108 [==============================] - 7s 63ms/step - loss: 0.0164 - val_loss: 0.0074\n",
      "Epoch 10/200\n",
      "108/108 [==============================] - 7s 66ms/step - loss: 0.0151 - val_loss: 0.0094\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_d,\n",
    "    train_d,\n",
    "    epochs=200,\n",
    "    batch_size=100,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the Training data Loss and Validation data Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TrainData and Get threshold(μ+3σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 7ms/step\n",
      "(12000, 164, 1)\n"
     ]
    }
   ],
   "source": [
    "#predict(train data)\n",
    "train_d_pred = model.predict(train_d)\n",
    "print(train_d_pred.shape)\n",
    "\n",
    "# ex) if trainTool is A or B reshape(1200×total_path, fq_num, 1) -> (1200×total_path, fq_num)\n",
    "#     if trainTool is C reshape(1023×total_path, fq_num, 1) -> (1023×total_path, fq_num)\n",
    "train_d_pred = train_d_pred.reshape(interval*total_path, fq_num)\n",
    "\n",
    "#再構成誤差計算\n",
    "train_mae_loss = np.mean(np.square(np.abs(train_d_pred - train_d)), axis=1)\n",
    "\n",
    "#再構成誤差の平均値\n",
    "train_mae_loss_mean = np.mean(train_mae_loss)\n",
    "\n",
    "#再構成誤差の標準偏差\n",
    "train_mae_loss_std = np.std(train_mae_loss)\n",
    "\n",
    "#閾値設定\n",
    "#閾値T = μ+3σ (μ:train_dの再構成誤差の平均値、σ:train_d（A（51~60path）200-300kHz）の再構成誤差のの標準偏差)\n",
    "\n",
    "threshold = train_mae_loss_mean + train_mae_loss_std * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024319136699250735\n",
      "0.03671900860908415\n",
      "0.13447616252650318\n"
     ]
    }
   ],
   "source": [
    "print(train_mae_loss_mean)\n",
    "print(train_mae_loss_std)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TestData and Get Reconstruction Error of TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17250/17250 [==============================] - 129s 7ms/step\n",
      "17250/17250 [==============================] - 128s 7ms/step\n",
      "14706/14706 [==============================] - 117s 8ms/step\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test(A,B,C 1-460pah) predict & reshape & get reconstruction error\n",
    "test_A_pred = model.predict(test_A)\n",
    "test_A_pred = test_A_pred.reshape(552000,164)\n",
    "\n",
    "test_B_pred = model.predict(test_B)\n",
    "test_B_pred = test_B_pred.reshape(552000,164)\n",
    "\n",
    "test_C_pred = model.predict(test_C)\n",
    "test_C_pred = test_C_pred.reshape(470580,164)\n",
    "\n",
    "\n",
    "test_A_mae_loss = np.mean(np.square(np.abs(test_A_pred - test_A)), axis=1)\n",
    "test_B_mae_loss = np.mean(np.square(np.abs(test_B_pred - test_B)), axis=1)\n",
    "test_C_mae_loss = np.mean(np.square(np.abs(test_C_pred - test_C)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552000,)\n",
      "(552000,)\n",
      "(470580,)\n"
     ]
    }
   ],
   "source": [
    "#RE は　Reconstruction Errorの略\n",
    "test_A_RE = test_A_mae_loss.reshape(-1)\n",
    "test_B_RE = test_B_mae_loss.reshape(-1)\n",
    "test_C_RE = test_C_mae_loss.reshape(-1)\n",
    "\n",
    "print(test_A_RE.shape)\n",
    "print(test_B_RE.shape)\n",
    "print(test_C_RE.shape)\n",
    "\n",
    "# save RE\n",
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_A\", test_A_RE)\n",
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_B\", test_B_RE)\n",
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_C\", test_C_RE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some calc for matching the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460.0\n",
      "460.0\n",
      "460.0\n"
     ]
    }
   ],
   "source": [
    "test_A_RE = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_A.npy\")\n",
    "test_B_RE = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_B.npy\")\n",
    "test_C_RE = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_C.npy\")\n",
    "\n",
    "print(len(test_A_RE)/1200)\n",
    "print(len(test_B_RE)/1200)\n",
    "print(len(test_C_RE)/1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_path_num\n",
    "a_p_n = 460\n",
    "#all_rotation_num\n",
    "a_r_n = 1200\n",
    "a_r_n_2 = 1023\n",
    "#moving avg path step\n",
    "m_a_p_s = 10\n",
    "\n",
    "w_size = a_r_n*m_a_p_s\n",
    "w_size2 = a_r_n_2*m_a_p_s\n",
    "\n",
    "x = np.linspace(-1,1,w_size)\n",
    "x2 = np.linspace(-1,1,w_size2)\n",
    "v = np.exp(-x**2 / 2) / np.sqrt(2 * np.pi)\n",
    "v2 = np.exp(-x2**2 / 2) / np.sqrt(2 * np.pi)\n",
    "v = v / np.sum(v)\n",
    "v2 = v2 / np.sum(v2)\n",
    "v = np.sort(v)[::-1]\n",
    "v2 = np.sort(v2)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RE_MA_A = np.convolve(test_A_RE,v, mode='valid')\n",
    "RE_MA_B = np.convolve(test_B_RE,v, mode='valid')\n",
    "RE_MA_C = np.convolve(test_C_RE,v2, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_A_MA\", RE_MA_A)\n",
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_B_MA\", RE_MA_B)\n",
    "np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_C_MA\", RE_MA_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\"A\", \"B\", \"C\"]\n",
    "intervals = [1200, 1200, 1023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450.0\n",
      "(12000, 45)\n",
      "(12000,)\n",
      "(12000, 1)\n",
      "(12000, 1)\n",
      "460.0\n",
      "-----------------\n",
      "450.0\n",
      "(12000, 45)\n",
      "(12000,)\n",
      "(12000, 1)\n",
      "(12000, 1)\n",
      "460.0\n",
      "-----------------\n",
      "450.0\n",
      "(10230, 45)\n",
      "(10230,)\n",
      "(10230, 1)\n",
      "(10230, 1)\n",
      "460.0\n",
      "(460, 1023)\n",
      "(460, 1200)\n",
      "460.0\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for tool, interval in zip(tools, intervals):\n",
    "    RE_MA = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_{tool}_MA.npy\")\n",
    "    new = RE_MA[:-1]\n",
    "    print(len(new)/interval)\n",
    "    new = new.reshape(interval*10, int(len(new)/(interval*10)))\n",
    "    print(new.shape)\n",
    "    avg = np.average(new,axis=1)\n",
    "    print(avg.shape)\n",
    "    avg = avg.reshape(len(avg),1)\n",
    "    print(avg.shape)\n",
    "    avg = np.repeat(avg, 1, axis=1)\n",
    "    print(avg.shape)\n",
    "    new_n = np.block([new,avg])\n",
    "    new_n = new_n.ravel()\n",
    "    print(len(new_n)/interval)\n",
    "    \n",
    "    if tool == \"C\":\n",
    "        new_nn = new_n.reshape(int(len(new_n)/interval), interval)\n",
    "        print(new_nn.shape)\n",
    "        hokan = 1200-1023\n",
    "        avg = np.average(new_nn, axis=1)\n",
    "        avg = avg.reshape(len(avg), 1)\n",
    "        avg = np.repeat(avg, hokan, axis=1)\n",
    "        new_nn  = np.block([new_nn, avg])\n",
    "        print(new_nn.shape)\n",
    "        new_nn = new_nn.ravel()\n",
    "        print(len(new_nn)/1200)\n",
    "        np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_{tool}_MA_EX.npy\",new_nn)\n",
    "    else:\n",
    "        np.save(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_{tool}_MA_EX.npy\",new_n)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_A_MA_EX.npy\")\n",
    "B = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_B_MA_EX.npy\")\n",
    "C = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\case{caseNum}_{trainTool}_C_MA_EX.npy\")\n",
    "\n",
    "A_ = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\hinan\\case{caseNum}_{trainTool}_A_MA_EX.npy\")\n",
    "B_ = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\hinan\\case{caseNum}_{trainTool}_B_MA_EX.npy\")\n",
    "C_ = np.load(rf\"Z:\\200 Produced_data\\MashineLearning\\RE\\hinan\\case{caseNum}_{trainTool}_C_MA_EX.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bbb5bf9d00>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(A)\n",
    "plt.plot(A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bbb5fe6820>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(B)\n",
    "plt.plot(B_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bbb6091c70>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(C)\n",
    "plt.plot(C_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bbb63920d0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(A)\n",
    "plt.plot(B)\n",
    "plt.plot(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bbb619e490>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(A_)\n",
    "plt.plot(B_)\n",
    "plt.plot(C_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb33ed1610>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "#all_path_num\n",
    "a_p_n = 300\n",
    "#all_rotation_num\n",
    "a_r_n = 1200\n",
    "#moving avg path step\n",
    "m_a_p_s = 30\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.set_xticks(np.arange(0, a_p_n*a_r_n + 1, a_r_n*m_a_p_s))\n",
    "ax.set_xticklabels(np.arange(0,a_p_n + 1,m_a_p_s))\n",
    "ax.set_xlabel(xlabel='Path Number')\n",
    "# ax.set_ylabel(ylabel='Cutting Force[N]')\n",
    "ax.tick_params(axis = 'x')\n",
    "ax.tick_params(axis = 'y')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.set_ylabel(ylabel='Reconstruction Error')\n",
    "\n",
    "\n",
    "# ax.plot(cfm_C, label=\"Cutting Force\", linewidth=\"5\")\n",
    "# ax2.plot(A_, label=\"Reconstruction Error\", color=\"magenta\")\n",
    "ax2.plot(A[:a_p_n*a_r_n])\n",
    "ax2.plot(B[:a_p_n*a_r_n])\n",
    "ax2.plot(C[:a_p_n*a_r_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
